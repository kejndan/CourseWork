\chapter{Реализация Selector of Algorithm Models}

Веб-приложение Selector of Algorithm Models можно разделить на две большие части: клиентская часть, которая будет видна пользователю, и серверная часть, она же будет называться алгоритмической. Элементы клиентской части будут показаны в разделе [??]. Остальные разделы будут посвящены алгоритмической части программы. 

\section{Схема работы программы}
Как показано на рисунке программа имеет следующие этапы:
\begin{itemize}
\item{\textbf{Загрузка пользовательских данных:}
\newline
В рамках данного блока программа получает на вход файл, который загрузил пользователь и отправляет его на сервер. Более подробно об этом будет сказано в разделе \ref{load}.
}
\item{\textbf{Предварительная обработка данных:}
\newline
Здесь программа позволяет выполнить предварительную обработку данных и увидеть их обновленный вид, после чего их можно отправить на анализ. Более подробно об этом будет сказано в разделе \ref{prepare}.
}
\item{\textbf{Автоматическое машинное обучение:}
\newline
В данном блоке происходит построение различных пайплайнов из алгоритмов на основании данных загруженных пользователем, после чего пользователю предлагаются лучшие из полученных пайплайнов. Более подробно об этом будет сказано в разделе \ref{construct}.
}
\item{\textbf{Работа с полученными результатами:}
\newline
В рамках данного блока пользователь сначала должен выбрать один из трёх лучших пайплайнов предложенных ему, после чего он может загрузить данные, которые уже не имеют множества целевых значений $Y$, а имеют только множество признаков $X$, после чего, с помощью выбранного пайплайна, будут получены значения для множества $ Y $. Более подробно об этом будет сказано в разделе \ref{completed}.
}
\end{itemize}
\section{Загрузка пользовательских данных}\label{load}
В данной части приложения пользователь должен подать на вход файл, который имеет расширение \textbf{csv}, и после чего отправить его на сервер. На сервере создается временный файл, в который копируется вся информация из переданного \textbf{csv} файла. После загрузки данных, сервер считывает все имена столбцов, если они не имеют имен, то он дает им имена \textbf{Feature i}, где i это порядковый номер столбца, а последнему столбцу, в случае отсутствия имени, он присваивает ему имя \textbf{Target}.

\section{Предварительная обработка данных}\label{prepare}
В данной части приложения пользователь будет иметь возможность внести следующие изменения в файл перед тем как его отправить на анализ данных~\cite{FeatureEngineering}~\cite{PreprocessingData}:

\begin{itemize}
\item{\textbf{Выбор множества признаков и множества допустимых значений:}
Пользователю предложен список, состоящий из названий признаков, и он сможет самостоятельно исключить те, которые он не хочет использовать при анализе.

Последний признак по умолчанию превращается в множество целевых значений, но если пользователь хочет, чтобы им был какой-то другой признак, то он может выбрать его из предложенного ему списка.
}

\item{\textbf{Выбор типа задачи:}
Пользователю предложен выбор между задачей регрессии и задачей классификации. По умолчанию ничего не выбрано.
}

\item{\textbf{Обработка пропущенных значений:}
Пользователь может выбрать обработать пропущенные значений в нужных ему признаках следующими методами:

\begin{itemize}
\item{\textbf{auto} -- 	Если количество пропущенных значений в признаке больше 80\%, то он удаляется, иначе пропущенные значения заменяются на средние арифметическое, а если это столбец с категориями, то замена на наиболее часто встречаемое значение.}
\item{\textbf{mean} -- Замена пропущенных значения признака на средние арифметическое столбца, а если это столбец с категориями, то замена на наиболее часто встречаемое значение. }
\item{\textbf{median} -- Замена пропущенного значения признака на медиану столбца, а если это столбец с категориями, то замена на наиболее часто встречаемое значение. }
\item{\textbf{most\_frequent} -- Замена пропущенного значения признака на наиболее часто встречаемое значение в данном столбце. }
\item{\textbf{del} -- Если объект содержит пропущенное значение, то он удаляется. }
\end{itemize}
}

\item{\textbf{Обработка выбросов:}
Пользователь может обработать выбросы в нужных ему признаках следующими методами:

\begin{itemize}
\item{\textbf{replace} -- Если значение признака больше процентиля 0.95, по всему столбцу, или меньше процентиля 0.05, то происходит замена этого значения на соответствующий процентиль.}
\item{\textbf{std} -- Если значение признака имеет отклонение превышающие стандартное отклонение в несколько раз, то объект удаляется.}
\item{\textbf{percentile} -- Если значение признака больше процентиля 0.95, по всему столбцу, или меньше процентиля 0.05, то объект удаляется.}
\end{itemize}

}

\item{\textbf{Категоризация:}
Пользователь может представить выбранные им признаки в виде категорий с помощью следующих методов:

\begin{itemize}
\item{\textbf{equal} -- Распределяет значения признака равномерно по заданному количеству категорий.} 
\item{\textbf{entropy} -- Разделяет признаки на категории на основании максимальной информативность по отношению к столбцу целевых значений. Это осуществляется с помощью Information Gain.}
\item{\textbf{quantile} -- Разделяет на категории с помощью квантилей.}
\end{itemize}
}
\item{\textbf{Трансформация:}
Пользователь может применить к выбранным признакам следующие математические функции:
\begin{itemize}
\item{\textbf{log} -- К значениям признака применяется функция натурального логарифма.} 
\item{\textbf{box-cox} -- К значениям признака применяется метод Бокса-Кокса.}
\end{itemize}
}

\item{\textbf{Нормализация:}
Пользователь может нормализовать выбранные им признаки следующими способами: 

\begin{itemize}
\item{\textbf{norm} -- Нормализация значений признака с помощью максимального и минимального значения в столбце.} 
\item{\textbf{stand} -- Нормализация признака с помощью его среднего значения и стандартного отклонения.}
\item{\textbf{l2-norm} -- Делит все значения признака на его норму.}
\end{itemize}
}
\end{itemize}

\section{Построение моделей машинного обучения}\label{construct}
После того как пользователь отправил датасет на анализ запускается алгоритм автоматического машинного обучения.

В статье ~\cite{TPOT} предлагается фреймворк для автоматического машинного обучения основанный на древовидной структуре пайплайна, которые будут улучшаться с помощью генетического алгоритма. Плюсом такой структуры является то, что она является очень гибкой для различных преобразований данных . Минусом является сложность подобной структур, которая сказывается на скорости работы. Здесь будет предложена более простая структура пайплайнов, которая работает по принципу очереди.

\subsection{Структура пайплайна}
Пусть длина пайплайна равняется трём, то есть он будет иметь три алгоритма. Так как алгоритмы машинного обучения являются терминальным алгоритмами, то он может быть только один, соответственно  остальные алгоритмы будут примитивными. Теперь в пустую очередь длины три, помещаются алгоритмы в следующем порядке, сначала туда помещается первый примитивный алгоритм, потом второй примитивный алгоритм, после чего туда помещается терминальный алгоритм.
Активация данного пайплайна будет происходить сначала очереди. 

\subsection{Примитивные и терминальные алгоритмы}
Примитивные алгоритмы можно разделить на два вида: трансформирующие и модифицирующие. Трансформирующими являются те алгоритмы, которые каким-то образом преобразуют значения, которые есть в датасете. А модифицирующими являются те, которые могут исключить какие-то признаки.

Список применяемых трансформирующих алгоритмов:
\begin{itemize}
\item{PolynomialFeatures (добавляет новые признаки через полиномиальную трансформацию)}
\item{StandardScaler (стандартизация)}
\item{RobustScaler (устранение выбросов через квантили)}
\item{MaxAbsScaler (нормализация с максимальным по модулю значением)}
\item{MinMaxScaler (линейная нормализация)}
\item{Binarizer (превращает значения либо в ноль, либо в единицу на основании заданного порога)}
\end{itemize}


Список применяемых модифицирующих алгоритмов:
\begin{itemize}
\item{VarianceThreshold (удаляет объекты с низкой дисперсией)}
\item{SelectKBest (выбирает k лучших признаков)}
\item{SelectPercentile (выбирает лучшие признаки по заданному процентилю)}
\item{SelectFwe (выбирает признаки на основании определенного уровня значимости)}
\item{RFE (рекурсивное исключение признаков с помощью заданного алгоритма машинного обучения)}
\item{SelectFromModel (выбирает признаки на основании их оценки заданным алгоритмом машинного обучения) }
\end{itemize}


Терминальные алгоритмы тоже делятся на два вида, одни для задачи восстановления регрессии, а другие для задачи классификации.

Список применяемых алгоритмов для задачи классификации:
\begin{itemize}
\item{GaussianNB, BernoulliNB, MultinomialNB (Наивный байесовский классификаторы)}
\item{DecisionTreeClassifier (Дерево решений)}
\item{ExtraTreesClassifier (Сверх-случайные леса)}
\item{RandomForestClassifier (Случайные леса)}
\item{GradientBoostingClassifier (Градиентный бустинг)}
\item{LogisticRegression (Логистическая регрессия)}
\item{KNeighborsClassifier (Метод K-ближайших соседей)}
\item{LinearSVC (Метод опорных векторов)}
\item{XGBClassifier}
\item{AdaBoostClassifier}
\item{SGDClassifier (Стохастический градиентный спуск)} 
\end{itemize}


Список применяемых алгоритмов для задачи восстановления регрессии:
\begin{itemize}
\item{ElasticNetCV (Эластичная сеть)}
\item{DecisionTreeRegressor (Дерево решений)}
\item{ExtraTreesRegressor (Сверх-случайные леса)}
\item{RandomForestRegressor (Случайные леса)}
\item{AdaBoostRegressor}
\item{GradientBoostingRegressor (Градиентный бустинг)}
\item{LassoLarsCV (Метод Лассо)}
\item{KNeighborsRegressor (Метод K-ближайших соседей)}
\item{LinearSVR (Метод опорных векторов)}
\item{RidgeCV (Ридж-регрессия)}
\item{XGBRegressor}
\item{SGDRegressor (Стохастический градиентный спуск)} 
\end{itemize}

Все перечисленные выше алгоритмы берутся из библиотеки scikit-learn. 

\subsection{Заполнение пайплайна алгоритмами}
Заполнение пайплайна алгоритмами происходит следующем образом:
\begin{enumerate}
\item{Выбирается случайная длина пайплайна $l$ в диапозоне от возможно минимально значения до максимально возможного.}
\item{Если $l\neq1$, то добавляем в пайплайн случайно выбранные примитивные алгоритмы в количестве $l-1$, для гиперпараметров алгоритма случайным образом берутся значения из множества возможных значений этого гиперпарметра.}
\item{В пайплайн добавляется терминальный алгоритм, который выбирается случайным образом, и также как в примитивных алгоритмах для гиперпараметров берутся значения.}
\item{Производится подсчёт уже готовых пайплайнов, имеющих те же самые алгоритмы, если оно превышает 5 \%, то пайплайн создается заново, иначе он добавляется в множество готовых пайплайнов.}
\end{enumerate}

О множестве возможных значений гиперпараметров для терминальных алгоритмов будет сказано в разделе \ref{hyperparam}.


\subsection{Структура генетического алгоритма}\label{struct}
Как было уже сказано, для поиска наилучшего пайплайна используется генетических алгоритм. Рассмотрим то, как устроен данный алгоритм конкретно для задачи автоматического машинного обучения. 

Как показано на рисунке [!!!] генетических алгоритм в данной задаче состоит из трех основных этапов и двух дополнительных, которые используется для создания самой первой популяции. 

\begin{itemize}
\item{\textbf{Создание первой популяции:}
В данном этапе создается заданное количество индивидов, которые конкретно здесь будут являться пайплайнами из алгоритмов. Значит создание первой популяции будет происходить с помощью многократного вызова функции заполнения пустого пайплайна.
}
\item{\textbf{Оценка первой популяции:}
В данном этапе с помощью функции оценки популяции, измеряется длина пайплайна и его точность  предсказания. 
}
\item{\textbf{Создание потомства:}
В данном этапе с помощью различных мутаций и скрещиваний создается потомство популяции.
}
\item{\textbf{Оценка потомства:}
В данном этапе вызывается функция оценки, которая замеряет длину пайплайна каждого индивида и его точность предсказания.
}
\item{\textbf{Селекция:}
В данном этапе происходит отбор лучших индивидов из популяции и его потомства для создания новой популяцию.
}
\end{itemize} 


\subsection{Создание потомства}
Потомство может создаваться двумя способами:
\begin{enumerate}
\item{Индивид из популяции скрещиваются и получается новый потомок, который будет иметь какие-то параметры от первого индивида, а какие-то от второго.}
\item{Индивид мутирует, то есть происходят какие-то изменения в его пайплайне.}
\end{enumerate}


В алгоритме \ref{alg:Create_offspring} приведен псевдокод создания нового потомства.  В данном примере вероятность мутации имеет значение 0.7, а вероятность скрещивания 0.3. Вероятность мутации имеет более высокое значение, потому что существует несколько видов мутаций. Также задается ограничение на количество одинаковых пайплайнов, чтобы избежать переполнения популяции однотипным вариантами решения.

\begin{algorithm}
\caption{Создание потомства}\label{alg:Create_offspring}
\begin{algorithmic}
\State $\textbf{INPUT}\  F_{population}$ -- популяция индивидов, $Size_{offspring}$ -- размер потомства
\State $\textbf{OUTPUT}\ F_{offspring}$
\State  $F_{offspring} \gets \{\}$, $Number_{offspring} \gets 0; $ 
\State $Probability\_mutation \gets 0.7, Probability\_mate \gets 0.3;$
\While{$ Number_{offspring} \le Size_{offspring}$}
\State $ p \gets random\_value(0,1);$
\If {$p <= Probability\_mate $}
\State $new\_individual \gets mate(random\_two\_ind\_for\_mate(F_{population}));$
\ElsIf {$p <= Probability\_mate + Probability\_mutation$}
\State $new\_individual \gets mutation(random\_choice(F_{population}));$
\EndIf
\If {$number\_identical\_ind(new\_individual) <=  Size_{offspring} * 0.1$}
\State $F_{offspring} \gets F_{offspring} \cup new\_individual;$
\State $Number_{offspring}++;$
\EndIf

\EndWhile
\end{algorithmic}
\end{algorithm}

\subsubsection{Мутации}
В рамках данной задачи мутации бывают трёх видов: 
\begin{itemize}
\item{\textbf{Replacement\_mutation:}
На вход данная мутация получает пайплайн индивида и после чего случайным образом оттуда выбирает алгоритм. С данным алгоритмом может произойти две вещи: замена значения гиперпараметра данного алгоритма на другое или замена самого алгоритма на другой (оба события равновероятны).
}
\item{\textbf{Shrink\_mutation:}
На вход данная мутация получает пайплайн индивида и после чего удаляет из него случайный примитивный алгоритм.
}
\item{\textbf{Insert\_mutation:}
На вход данная мутация получает пайплайн индивида и после чего добавляет в него случайный примитивный алгоритм.
}
\end{itemize}

Все вышеперечисленные мутации равновероятны.

\subsubsection{Скрещивание}
На вход функции скрещивания передаются два случайных индивида, но при условие что у них есть хотя бы один общий алгоритм. После чего случайным образом выбирается общий алгоритм у этих индивидом, и аналогичным способом выбирается гиперпараметр, который будет заменен.

Построение нового индивида происходит следующем образом, копируется первый инвидивид и на место значения выбранного гиперпараметра вставляет значение гиперпараметра из второго индивида.

Также была рассмотрена возможность выбора гиперпараметра для замены, в том случае если это терминальный алгоритм, с помощью \textbf{GridSearchCV} (функция из библиотеки \textbf{scikit-learn}, которая выбирает лучшие значения гиперпараметров из тех, которые были переданы в нее), то есть передаются значения гиперпарметров из терминального алгоритма первого индивида и второго, а после данная функция возвращает те значения для гиперпараметров, которые дали наилучший результат и после чего они записывались в нового индивида. Но точность получаемого пайплайна оставалась примерно той же, но время работы алгоритма значительно увеличивалось. Поэтому данный способ замены не используется.

\subsection{Функция оценки}
Данная функция используется для оценки индивидов из популяции или потомства. Она использует обычную кросс-валидацию по пайплайну каждого индивида на обучающей выборки. После чего в атрибут индивида записываются данные об его оценки в формате (длина пайплайна, оценка качества пайплайна).

В зависимости от задачи оценка качества происходит по разным метрикам. Метрикой по умолчанию для задачи восстановления регрессии является отрицательная среднеквадратичная ошибка, а для задачи классификации F-мера.

\subsection{Селекция}
Данная функция на вход получает популяцию, потомство и каким должен быть размер новой популяции после селекции. Для селекции используется алгоритм \textbf{ NSGA-II }\cite{NSGA}, которые является алгоритмом многокритериальной оптимизации. Он выполняет сортировку на основании Рангов границы Парето и достижения максимальной разреженности.  Что позволяет конкретно в рамках данной задачи достичь того, чтобы в приоритете при селекции были те пайплайны, которые имеют наименьшую длину и имеют наибольшую оценку, но при этом они должны быть максимально разрежены в рамках своих критериев, что позволяет сохранять многообразие пайплайнов при селекции.

\subsection{Алгоритм автоматического машинного обучения}
В подразделе \ref{struct} было рассказано о структуре генетического алгоритма. В алгоритме \ref{alg:fit} будет представлен псевдокод функции обучения для переданных в нее данных. 

\begin{algorithm}
\caption{Обучение}\label{alg:fit}
\begin{algorithmic}
\State $\textbf{INPUT}\  Size_{offspring}, Size_{population}, N_{generations}, Features, Targets$
\State $F_{population} \gets create\_population(Size_{population})$;
\State $evaluate(F_{population},Features, Targets)$;
\For{$generation \gets 1, N_{generations}$}
\State $F_{offspring} \gets create\_offspring(F_{population}, Size_{offspring})$;
\State $evaluate(F_{offspring}, Features, Targets)$;
\State $F_{population} \gets select(F_{population}, F_{offspring}, Size_{population})$;
\EndFor
\end{algorithmic}
\end{algorithm}

После завершения работы данной функции информация о последнем популяции сохраняется как атрибут класса.

Для того чтобы получить итоговый пайплайн требуется вызвать функцию получения наилучшего индивида последний популяции. Функция на вход получает тестовую выборку, после чего эта тестовая выборка разбивается на валидационную и тестовую. Происходит валидация и после чего пайплайн с наилучшим результатом на валидационной выборке, проверяется на тестовой. И результатом возвращаемым функцией является пайплайн с самой высокой точностью на валидационной выборке и его результат на тестовой.

\subsection{Использование алгоритма в веб-приложении}
Сервер вызывает описанный выше алгоритм со следующими параметрами:
\begin{itemize}
\item{$Size_{population} \gets 50$}
\item{$Size_{offspring} \gets 50$}
\item{$N_{generations} \gets 5$}
\end{itemize}
Также функция получения наилучшего пайплайна имеет небольшую надстройку, после замера на валидационной выборке три лучших пайплайна сохраняются и далее пользователю будет предложено самому выбрать какой из них использовать.

\section{Работа с полученными результатами}\label{completed}
После того как алгоритм автоматического обучения закончиться пользователю будет предложено выбрать из трёх лучших пайплайнов для дальнейший работы, но это возможно после того, как пользователь загрузит датасет, в котором отсутствует множество целевых значений. 

После этого пользователь сможет запустить выбранный пайплайн для предсказания множества целевых значений у переданного датасета.

\section{Клиентская часть веб-приложения}\label{client}



